{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filtering nifty 50 stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### have to create for whole nse stocks and bse stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import nsetools as nt\n",
    "import pickle as pkl\n",
    "import pyttsx3\n",
    "engine = pyttsx3.init() \n",
    "voice_id = \"HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Speech\\Voices\\Tokens\\TTS_MS_EN-US_DAVID_11.0\"\n",
    "# Use male voice \n",
    "engine.setProperty('voice', voice_id) \n",
    "newVoiceRate = 180\n",
    "engine.setProperty('rate',newVoiceRate)\n",
    "engine.say('Hello Sir. Welcome to stock screening')\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.niftyindices.com/IndexConstituent/ind_nifty50list.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j\n"
     ]
    }
   ],
   "source": [
    "print(\"j\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ind_nifty50list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kiran\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = data['Symbol']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = symbols.copy()\n",
    "timeframes = ['15m']\n",
    "data = []\n",
    "date = \"2020-12-07\"\n",
    "#end_date = \"2020-12-11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "ADANIPORTS\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ASIANPAINT\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "AXISBANK\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BAJAJ-AUTO\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BAJFINANCE\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BAJAJFINSV\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BPCL\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BHARTIARTL\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BRITANNIA\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "CIPLA\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "COALINDIA\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "DIVISLAB\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "DRREDDY\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "EICHERMOT\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "GAIL\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "GRASIM\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "HCLTECH\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "HDFCBANK\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "HDFCLIFE\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "HEROMOTOCO\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "HINDALCO\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "HINDUNILVR\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "HDFC\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ICICIBANK\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ITC\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "IOC\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "INDUSINDBK\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "INFY\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "JSWSTEEL\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "KOTAKBANK\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "LT\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "M&M\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "MARUTI\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "NTPC\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "NESTLEIND\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ONGC\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "POWERGRID\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "RELIANCE\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "SBILIFE\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "SHREECEM\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "SBIN\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "SUNPHARMA\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "TCS\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "TATAMOTORS\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "TATASTEEL\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "TECHM\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "TITAN\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "UPL\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ULTRACEMCO\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "WIPRO\n"
     ]
    }
   ],
   "source": [
    "#creating and saving all companies 5m data into data dictionary\n",
    "timeframes = ['15m']\n",
    "data = []\n",
    "i = 0\n",
    "for company in companies:\n",
    "    for time in timeframes:\n",
    "        data.append(yf.download(                     # or pdr.get_data_yahoo(...)\n",
    "            tickers = company + \".NS\",\n",
    "            interval = time ,\n",
    "            start = date,\n",
    "            #end =  end_date ,\n",
    "            group_by = 'ticker',\n",
    "        ) )\n",
    "        i=i+1\n",
    "        print(company)\n",
    "with open('nifty.pkl','wb') as f:\n",
    "    pkl.dump(data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(475, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "ADANIPORTS\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ASIANPAINT\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "AXISBANK\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BAJAJ-AUTO\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BAJFINANCE\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BAJAJFINSV\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BPCL\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BHARTIARTL\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BRITANNIA\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "CIPLA\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "COALINDIA\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "DIVISLAB\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "DRREDDY\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "EICHERMOT\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "GAIL\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "GRASIM\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "HCLTECH\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "HDFCBANK\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "HDFCLIFE\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "HEROMOTOCO\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "HINDALCO\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "HINDUNILVR\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "HDFC\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ICICIBANK\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ITC\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "IOC\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "INDUSINDBK\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "INFY\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "JSWSTEEL\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "KOTAKBANK\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "LT\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "M&M\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "MARUTI\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "NTPC\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "NESTLEIND\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ONGC\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "POWERGRID\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "RELIANCE\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "SBILIFE\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "SHREECEM\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "SBIN\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "SUNPHARMA\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "TCS\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "TATAMOTORS\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "TATASTEEL\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "TECHM\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "TITAN\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "UPL\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ULTRACEMCO\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "WIPRO\n"
     ]
    }
   ],
   "source": [
    "#creating and saving all companies 5m data into data dictionary\n",
    "timeframes = ['15m']\n",
    "data = []\n",
    "i = 0\n",
    "for time in timeframes:\n",
    "    for company in companies:\n",
    "        data.append(yf.download(                     # or pdr.get_data_yahoo(...)\n",
    "            tickers = company + \".NS\",\n",
    "            interval = time ,\n",
    "            start = date,\n",
    "            #end =  end_date ,\n",
    "            group_by = 'ticker',\n",
    "        ) )\n",
    "        i=i+1\n",
    "        print(company)\n",
    "with open('nifty.pkl','wb') as f:\n",
    "    pkl.dump(data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nifty.pkl','rb') as f:\n",
    "    data = pkl.load(f)\n",
    "today_companies = []\n",
    "high_companies = []\n",
    "low_companies = []\n",
    "for i in range(len(companies)):\n",
    "    high_param = data[i]['High'][0] +1\n",
    "    low_param = data[i]['Low'][0] -1\n",
    "    check_high = np.any(data[i]['Open'] > high_param) or np.any(data[i]['Close'] > high_param)\n",
    "    if check_high:\n",
    "        high_companies.append(companies[i])\n",
    "    check_low = np.any(data[i]['Open'] < low_param) or np.any(data[i]['Close'] < low_param)\n",
    "    if check_low:\n",
    "        low_companies.append(companies[i])        \n",
    "    sufficient = (check_high or check_low) == 0 #checking suffiecient or not and inversing answer\n",
    "    if sufficient:\n",
    "        today_companies.append(companies[i])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today_companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ikkadara reyyyy..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# list of stratagies from desired date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-11-01',\n",
       " '2020-11-02',\n",
       " '2020-11-03',\n",
       " '2020-11-04',\n",
       " '2020-11-05',\n",
       " '2020-11-06',\n",
       " '2020-11-07',\n",
       " '2020-11-08',\n",
       " '2020-11-09',\n",
       " '2020-11-10',\n",
       " '2020-11-11',\n",
       " '2020-11-12',\n",
       " '2020-11-13',\n",
       " '2020-11-14',\n",
       " '2020-11-15',\n",
       " '2020-11-16',\n",
       " '2020-11-17',\n",
       " '2020-11-18',\n",
       " '2020-11-19',\n",
       " '2020-11-20',\n",
       " '2020-11-21',\n",
       " '2020-11-22',\n",
       " '2020-11-23',\n",
       " '2020-11-24',\n",
       " '2020-11-25',\n",
       " '2020-11-26',\n",
       " '2020-11-27']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = \"2020-12-01\"\n",
    "end_date = \"2020-12-30\"\n",
    "dates = [(\"2020-11-\" + \"0\"+str(i) if i<10 else \"2020-11-\"+str(i))for i in range(1,28)]\n",
    "period = 25\n",
    "#dates.remove(\"2020-11-14\")\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "ADANIPORTS\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ASIANPAINT\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "AXISBANK\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BAJAJ-AUTO\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BAJFINANCE\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BAJAJFINSV\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BPCL\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BHARTIARTL\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BRITANNIA\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "CIPLA\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "COALINDIA\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "DIVISLAB\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "DRREDDY\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "EICHERMOT\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "GAIL\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "GRASIM\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "HCLTECH\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "HDFCBANK\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "HDFCLIFE\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "HEROMOTOCO\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "HINDALCO\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "HINDUNILVR\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "HDFC\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ICICIBANK\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ITC\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "IOC\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "INDUSINDBK\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "INFY\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "JSWSTEEL\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "KOTAKBANK\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "LT\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "M&M\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "MARUTI\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "NTPC\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "NESTLEIND\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ONGC\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "POWERGRID\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "RELIANCE\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "SBILIFE\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "SHREECEM\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "SBIN\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "SUNPHARMA\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "TCS\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "TATAMOTORS\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "TATASTEEL\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "TECHM\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "TITAN\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "UPL\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ULTRACEMCO\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "WIPRO\n"
     ]
    }
   ],
   "source": [
    "#creating and saving all companies 5m data into data dictionary\n",
    "engine.say('data downloading started')\n",
    "engine.runAndWait()\n",
    "timeframes = ['15m']\n",
    "whole_data = []\n",
    "i = 0\n",
    "for time in timeframes:\n",
    "    for company in companies:\n",
    "        whole_data.append(yf.download(                     # or pdr.get_data_yahoo(...)\n",
    "            tickers = company + \".NS\",\n",
    "            interval = time ,\n",
    "            start = start_date,\n",
    "            end =  end_date ,\n",
    "            group_by = 'ticker',\n",
    "        ) )\n",
    "        i=i+1\n",
    "        print(company)\n",
    "with open('data.pkl','wb') as f:\n",
    "    pkl.dump(whole_data,f)\n",
    "engine.say('data ready for furthur process')\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data set creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_dates={}\n",
    "for date in dates:\n",
    "    data_with_dates[date] = set()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_companies = {}\n",
    "for company in companies:\n",
    "    data_with_companies[company] = set()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'2020-12-15'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-23afcd64dcfb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0msufficient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcheck_high\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mcheck_low\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;31m#checking suffiecient or not and inversing answer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msufficient\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                 \u001b[0mdata_with_dates\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwhole_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompanies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'stocks screening completed. Now you can proceed'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '2020-12-15'"
     ]
    }
   ],
   "source": [
    "engine.say('logic start for, date wise company data')\n",
    "engine.runAndWait()\n",
    "with open('data.pkl','rb') as f:\n",
    "    whole_data = pkl.load(f)\n",
    "for i in range(len(companies)):\n",
    "    for length in range(int( whole_data[i].shape[0]/25) ):\n",
    "            high_param = whole_data[i]['High'][length*25:(length+1)*25][0]\n",
    "            low_param = whole_data[i]['Low'][length*25:(length+1)*25][0] \n",
    "            check_high = np.any(whole_data[i]['Open'][length*25:(length+1)*25] > high_param) or np.any(whole_data[i]['Close'][length*25:(length+1)*25] > high_param)\n",
    "            check_low = np.any(whole_data[i]['Open'][length*25:(length+1)*25] < low_param) or np.any(whole_data[i]['Close'][length*25:(length+1)*25] < low_param)\n",
    "            sufficient = (check_high or check_low) == 0 #checking suffiecient or not and inversing answer\n",
    "            if sufficient:\n",
    "                data_with_dates[ str(whole_data[i].index[length*25:(length+1)*25][0])[:10] ].add(companies[i])            \n",
    "\n",
    "engine.say('stocks screening completed. Now you can proceed')\n",
    "engine.runAndWait()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2020-11-01': set(),\n",
       " '2020-11-02': {'JSWSTEEL', 'M&M', 'TATAMOTORS', 'UPL'},\n",
       " '2020-11-03': {'JSWSTEEL', 'MARUTI'},\n",
       " '2020-11-04': {'HCLTECH',\n",
       "  'HDFCLIFE',\n",
       "  'INFY',\n",
       "  'ONGC',\n",
       "  'POWERGRID',\n",
       "  'SBILIFE',\n",
       "  'TCS',\n",
       "  'TECHM',\n",
       "  'WIPRO'},\n",
       " '2020-11-05': {'BAJAJ-AUTO',\n",
       "  'HCLTECH',\n",
       "  'HDFCBANK',\n",
       "  'HEROMOTOCO',\n",
       "  'SBIN',\n",
       "  'TATAMOTORS'},\n",
       " '2020-11-06': {'ONGC', 'POWERGRID', 'TATAMOTORS', 'WIPRO'},\n",
       " '2020-11-07': set(),\n",
       " '2020-11-08': set(),\n",
       " '2020-11-09': {'BRITANNIA', 'INFY', 'ITC'},\n",
       " '2020-11-10': {'ICICIBANK', 'MARUTI'},\n",
       " '2020-11-11': {'MARUTI'},\n",
       " '2020-11-12': {'BHARTIARTL', 'COALINDIA', 'TECHM'},\n",
       " '2020-11-13': {'BRITANNIA', 'GAIL', 'HDFCBANK', 'MARUTI'},\n",
       " '2020-11-15': set(),\n",
       " '2020-11-16': set(),\n",
       " '2020-11-17': set(),\n",
       " '2020-11-18': set(),\n",
       " '2020-11-19': set(),\n",
       " '2020-11-20': {'DRREDDY'},\n",
       " '2020-11-21': set(),\n",
       " '2020-11-22': set(),\n",
       " '2020-11-23': set(),\n",
       " '2020-11-24': {'UPL'},\n",
       " '2020-11-25': set(),\n",
       " '2020-11-26': {'RELIANCE'},\n",
       " '2020-11-27': set()}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.say('logic start for, company wise date data')\n",
    "engine.runAndWait()\n",
    "with open('data.pkl','rb') as f:\n",
    "    whole_data = pkl.load(f)\n",
    "for length in range(int( whole_data[i].shape[0]/25) ):\n",
    "    for i in range(len(companies)):\n",
    "        \n",
    "            high_param = whole_data[i]['High'][length*25:(length+1)*25][0]\n",
    "            low_param = whole_data[i]['Low'][length*25:(length+1)*25][0] \n",
    "            check_high = np.any(whole_data[i]['Open'][length*25:(length+1)*25] > high_param) or np.any(whole_data[i]['Close'][length*25:(length+1)*25] > high_param)\n",
    "            check_low = np.any(whole_data[i]['Open'][length*25:(length+1)*25] < low_param) or np.any(whole_data[i]['Close'][length*25:(length+1)*25] < low_param)\n",
    "            sufficient = (check_high or check_low) == 0 #checking suffiecient or not and inversing answer\n",
    "            if sufficient:\n",
    "                data_with_companies[companies[i]].add(str(whole_data[i].index[length*25:(length+1)*25][0])[:10] )            \n",
    "engine.say('stocks screening completed. Now you can proceed')\n",
    "engine.runAndWait()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADANIPORTS': set(),\n",
       " 'ASIANPAINT': {'2020-12-15'},\n",
       " 'AXISBANK': {'2020-12-03', '2020-12-07', '2020-12-15'},\n",
       " 'BAJAJ-AUTO': {'2020-12-08'},\n",
       " 'BAJFINANCE': set(),\n",
       " 'BAJAJFINSV': set(),\n",
       " 'BPCL': set(),\n",
       " 'BHARTIARTL': set(),\n",
       " 'BRITANNIA': {'2020-12-03', '2020-12-14', '2020-12-16'},\n",
       " 'CIPLA': {'2020-12-16'},\n",
       " 'COALINDIA': set(),\n",
       " 'DIVISLAB': {'2020-12-18'},\n",
       " 'DRREDDY': set(),\n",
       " 'EICHERMOT': {'2020-12-09'},\n",
       " 'GAIL': {'2020-12-03',\n",
       "  '2020-12-07',\n",
       "  '2020-12-09',\n",
       "  '2020-12-15',\n",
       "  '2020-12-23'},\n",
       " 'GRASIM': set(),\n",
       " 'HCLTECH': {'2020-12-16', '2020-12-23'},\n",
       " 'HDFCBANK': set(),\n",
       " 'HDFCLIFE': {'2020-12-09'},\n",
       " 'HEROMOTOCO': {'2020-12-04'},\n",
       " 'HINDALCO': set(),\n",
       " 'HINDUNILVR': {'2020-12-08'},\n",
       " 'HDFC': {'2020-12-23'},\n",
       " 'ICICIBANK': set(),\n",
       " 'ITC': {'2020-12-04', '2020-12-16'},\n",
       " 'IOC': {'2020-12-11', '2020-12-14', '2020-12-23'},\n",
       " 'INDUSINDBK': set(),\n",
       " 'INFY': set(),\n",
       " 'JSWSTEEL': {'2020-12-03'},\n",
       " 'KOTAKBANK': {'2020-12-08'},\n",
       " 'LT': {'2020-12-03'},\n",
       " 'M&M': set(),\n",
       " 'MARUTI': {'2020-12-02', '2020-12-09', '2020-12-10'},\n",
       " 'NTPC': set(),\n",
       " 'NESTLEIND': {'2020-12-03', '2020-12-17', '2020-12-23'},\n",
       " 'ONGC': {'2020-12-07', '2020-12-09', '2020-12-15'},\n",
       " 'POWERGRID': {'2020-12-23'},\n",
       " 'RELIANCE': set(),\n",
       " 'SBILIFE': {'2020-12-10'},\n",
       " 'SHREECEM': {'2020-12-22'},\n",
       " 'SBIN': {'2020-12-11'},\n",
       " 'SUNPHARMA': set(),\n",
       " 'TCS': set(),\n",
       " 'TATAMOTORS': set(),\n",
       " 'TATASTEEL': set(),\n",
       " 'TECHM': set(),\n",
       " 'TITAN': {'2020-12-08'},\n",
       " 'UPL': {'2020-12-14'},\n",
       " 'ULTRACEMCO': set(),\n",
       " 'WIPRO': {'2020-12-07'}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(companies)):\n",
    "    high_param = data[i]['High'][0]\n",
    "    low_param = data[i]['Low'][0] \n",
    "    check_high = np.any(data[i]['Open'] > high_param) or np.any(data[i]['Close'] > high_param)\n",
    "    check_low = np.any(data[i]['Open'] < low_param) or np.any(data[i]['Close'] < low_param)\n",
    "    sufficient = (check_high or check_low) == 0 #checking suffiecient or not and inversing answer\n",
    "    if sufficient:\n",
    "        today_companies.append(companies[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fundamentally strong companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'strong_stocks1.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-cc198cf30b18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'strong_stocks1.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcompanies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Ticker'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m                 )\n\u001b[0;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         raise ValueError(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine)\u001b[0m\n\u001b[0;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"xlrd\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# a ZIP file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'strong_stocks1.xlsx'"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel('strong_stocks1.xlsx')\n",
    "companies = data['Ticker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nt.Nse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "INFY nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ITC nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "HINDZINC nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BAJAJ-AUTO nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "HEROMOTOCO nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "GLAND nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "NMDC nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "IGL nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BEL nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "OFSS nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "LTTS nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "AIAENG nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ATUL nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "SUNTV nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "COFORGE nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "AJANTPHARM nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "NAVINFLUOR nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "CASTROLIND nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "VINATIORGA nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "MGL nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "TIMKEN nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ERIS nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "UTIAMC nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "RITES nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "IEX nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BDL nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "VSTIND nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "FDC nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "RALLIS nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "FINCABLES nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ENGINERSIN nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "COCHINSHIP nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "MAZDOCK nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "JUSTDIAL nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "CAPLIPOINT nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "NESCO nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "STARCEMENT nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ADVENZYMES nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "DHANUKA nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "KSCL nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BAJAJCON nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ICRA nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "TRITURBINE nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ORIENTREF nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "LAOPALA nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "SHARDACROP nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "NOCIL nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "KIRIINDUS nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "GREAVESCOT nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "SWARAJENG nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "CARERATING nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "MAITHANALL nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "TVTODAY nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "MAYURUNIQ nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "HINDOILEXP nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "PAUSHAKLTDbse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "SASKEN nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "KSL nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "DOLAT nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "SESHAPAPER nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "GRAUWEILbse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BLS nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "FOSECOIND nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "EIHAHOTELS nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BLILbse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "GMBREW nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ULTRAMARbse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "SIRCA nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "MPSLTD nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BHAGERIA nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "UNIDT nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "EXPLEOSOL nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "WIMPLASTbse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "LINCOLN nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "STOVACQbse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "CONTROLPR nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "DIAMINESQbse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ELDEHSGbse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "GANDHITUBE nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ADVANIHOTR nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- MANAS.BO: No data found for this date range, symbol may be delisted\n",
      "MANASbse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "MULTIBASEbse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "PANCARBONbse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "JENBURPHbse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "REPL nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "AKSHARCHEM nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "KANCHIbse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "AVANTELbse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "CHEMCRUXbse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- EMKAYTOOLS.BO: No data found, symbol may be delisted\n",
      "EMKAYTOOLSbse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "DHPINDbse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "GLOBAL nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "DECCANbse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "PRESSMN nse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "7TECbse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "SAGARSOFTbse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "MYSORPETRObse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "VRLbse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BOMBCYCbse\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "POOJAENTbse\n"
     ]
    }
   ],
   "source": [
    "#creating and saving all companies 5m data into data dictionary\n",
    "check = nt.Nse()\n",
    "timeframes = ['15m']\n",
    "data = []\n",
    "i = 0\n",
    "for time in timeframes:\n",
    "    for company in companies:\n",
    "        a = check.is_valid_code(company)\n",
    "        if a :            \n",
    "            data.append(yf.download(                     # or pdr.get_data_yahoo(...)\n",
    "            tickers = company + \".NS\",\n",
    "            interval = time ,\n",
    "            start = date,\n",
    "            # end ='2020-09-01',\n",
    "            group_by = 'ticker',\n",
    "            ) )\n",
    "            i=i+1\n",
    "            print(company+\" nse\")\n",
    "        else:\n",
    "            data.append(yf.download(                     # or pdr.get_data_yahoo(...)\n",
    "            tickers = company + \".BO\",\n",
    "            interval = time ,\n",
    "            start =date,\n",
    "            # end ='2020-09-01',\n",
    "            group_by = 'ticker',\n",
    "            ) )\n",
    "            i=i+1\n",
    "            print(company+\"bse\")\n",
    "            \n",
    "with open('strong.pkl','wb') as f:\n",
    "    pkl.dump(data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
       "Index: []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[-11].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptions = ['MAITHANALL', 'UNIDT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MANAS nothere\n",
      "EMKAYTOOLS nothere\n"
     ]
    }
   ],
   "source": [
    "with open('strong.pkl','rb') as f:\n",
    "    data = pkl.load(f)\n",
    "today_companies = []\n",
    "for i in range(len(companies)):\n",
    "    try:\n",
    "    \n",
    "        if data[i]['Close'][-1] < 100:\n",
    "            continue\n",
    "        high_param = data[i]['High'][0]\n",
    "        low_param = data[i]['Low'][0] \n",
    "        check_high = np.any(data[i]['Open'] >= high_param) or np.any(data[i]['Close'] >= high_param)\n",
    "        check_low = np.any(data[i]['Open'] <= low_param) or np.any(data[i]['Close'] <= low_param)\n",
    "        sufficient = (check_high or check_low) == 0 #checking suffiecient or not and inversing answer\n",
    "        if sufficient:\n",
    "            today_companies.append(companies[i])\n",
    "    \n",
    "    except:\n",
    "        print(companies[i]+\" nothere\")\n",
    "        i = i+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FINCABLES', 'EIHAHOTELS']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today_companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSE Companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nse = nt.nse.Nse()\n",
    "data = nse.get_stock_codes()\n",
    "index = np.random.permutation(len(list(data.keys())))\n",
    "company = np.array(list(data.values()))\n",
    "companies = np.array(list(data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = companies[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_comp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed()\n",
    "nse = nt.nse.Nse()\n",
    "data = nse.get_stock_codes()\n",
    "index = np.random.permutation(len(list(data.keys())))\n",
    "company = np.array(list(data.values()))\n",
    "companies = np.array(list(data.keys()))\n",
    "comp = companies[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for co in comp:\n",
    "    tick = yf.Ticker(co+\".NS\")\n",
    "    try:\n",
    "        info = tick.info\n",
    "        if info['marketCap'] > 200000000000 and info['averageVolume'] >= 10000000:\n",
    "            good_comp.append(co)\n",
    "            print(co)\n",
    "    except:\n",
    "        print(\"no \"+co)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a  = list(data.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating and saving all companies 15m data into data dictionary\n",
    "timeframes = ['15m']\n",
    "data = []\n",
    "i = 0\n",
    "for company in companies:\n",
    "    for time in timeframes:\n",
    "        print(company)\n",
    "        data.append(yf.download(                     # or pdr.get_data_yahoo(...)\n",
    "            tickers = company + \".NS\",\n",
    "            interval = time ,\n",
    "            start =date,\n",
    "           # end ='2020-09-01',\n",
    "            group_by = 'ticker',\n",
    "        ) );\n",
    "        i=i+1;\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_companies = []\n",
    "for i in range(len(companies)):\n",
    "    if data[i]['Close'][-1] < 400:\n",
    "        continue\n",
    "    high_param = data[i]['High'][0]\n",
    "    low_param = data[i]['Low'][0]\n",
    "    check_high = np.any(data[i]['Open'] > high_param) or np.any(data[i]['Close'] > high_param)\n",
    "    check_low = np.any(data[i]['Open'] < low_param) or np.any(data[i]['Close'] < low_param)\n",
    "    sufficient = (check_high or check_low) == 0 #checking suffiecient or not and inversing answer\n",
    "    if sufficient:\n",
    "        today_companies.append(companies[i])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dont_want = [ 'AGCNET',\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trying for bse but not accepting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bsedata.bse import BSE\n",
    "bse = BSE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bse.updateScripCodes()\n",
    "bse_data = bse.getScripCodes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = list(bse_data.keys())[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = yf.download(                     # or pdr.get_data_yahoo(...)\n",
    "            tickers = list(companies+ \".BO\") ,\n",
    "            interval = time ,\n",
    "            start ='2020-12-18',\n",
    "           # end ='2020-09-01',\n",
    "            group_by = 'ticker',\n",
    "            auto_adjust=True,\n",
    "        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating and saving all companies 5m data into data dictionary\n",
    "timeframes = ['15m']\n",
    "i = 0\n",
    "for company in companies:\n",
    "    for time in timeframes:\n",
    "        data.append(yf.download(                     # or pdr.get_data_yahoo(...)\n",
    "            tickers = company + \".BO\",\n",
    "            interval = time ,\n",
    "            start ='2020-12-18',\n",
    "           # end ='2020-09-01',\n",
    "            group_by = 'ticker',\n",
    "        ) )\n",
    "        i=i+1\n",
    "        print(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_companies = []\n",
    "for i in range(len(companies)):\n",
    "    high_param = data[i]['High'][0]\n",
    "    low_param = data[i]['Low'][0]\n",
    "    check_high = np.any(data[i]['Open'] > high_param) or np.any(data[i]['Close'] > high_param)\n",
    "    check_low = np.any(data[i]['Open'] < low_param) or np.any(data[i]['Close'] < low_param)\n",
    "    sufficient = (check_high or check_low) == 0 #checking suffiecient or not and inversing answer\n",
    "    if sufficient:\n",
    "        today_companies.append(companies[i])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
